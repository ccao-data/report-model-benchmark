---
format: gfm
---

This repository compares the time-to-train of two gradient-boosted decision tree (GBDT) frameworks - LightGBM and XGBoost - across different hardware and versions. The purpose of this comparison is to help the CCAO make two decisions:

1. Which GBDT framework to use for its 2024 automated valuation models
2. Whether or not to purchase additional hardware (a GPU) in order to improve model training speed

Below are the results of our tests. 

> ***:warning: Please note that the performance statistics presented here are only for cross-model comparison and do not reflect any real model results e.g. they are included only to show that each GBDT framework and version generates similar results, given the same data.***

<h2 id="results">LightGBM CPU/GPU vs XGBoost CPU/GPU</h2>

```{r setup, echo=FALSE, message=FALSE}
library(arrow)
library(dplyr)
library(gt)
library(kableExtra)
library(purrr)
library(readr)

model_specs <- read_csv("input/model_specs.csv") %>%
  mutate(
    across(starts_with("Approx") & where(is.character), ~ parse_number(.x))
  ) %>%
  select(Key:`Approx. Peak Device Utilization`)

perf_df <- map_dfr(
  list.files("output/performance", pattern = "*.parquet", full.names = TRUE),
  read_parquet
)

time_df <- map_dfr(
  list.files("output/timing", pattern = "*.parquet", full.names = TRUE),
  read_parquet
) %>%
  select(-c(tic, toc)) %>%
  tidyr::pivot_wider(id_cols = run_id, names_from = stage, values_from = time)

full_data <- model_specs %>%
  left_join(time_df, by = c("Key" = "run_id")) %>%
  left_join(perf_df, by = c("Key" = "run_id")) %>%
  select(-c(Key, time)) %>%
  rename(
    `Wall Time (Full Run)` = train,
    `Wall Time (Prediction)` = predict,
    `Wall Time (SHAP)` = shap,
    r2 = rsq
  ) %>%
  rename_with(toupper, rmse:mki) %>%
  mutate(
    `Approx. Peak Device Utilization` = `Approx. Peak Device Utilization` / 100,
    MAPE = MAPE / 100
  )
```

```{r create_table, echo=FALSE, message=FALSE}
full_data %>%
  select(-`Hardware Specifications`) %>%
gt() %>%
  tab_header(title = "LightGBM CPU/GPU vs XGBoost CPU/GPU") %>%
  tab_footnote(footnote = "1", locations = cells_body(Type, c(3, 7, 8))) %>%
  tab_footnote(footnote = "2", locations = cells_body(Type, 6)) %>%
  fmt_percent(starts_with("Approx."), decimals = 0) %>%
  fmt_percent(MAPE, decimals = 2) %>%
  fmt_duration(
    starts_with("Wall Time"),
    input_units = "seconds",
    output_units = c("hours", "minutes", "seconds")
  ) %>%
  fmt_currency(c(contains("RMSE"), contains("MAE")), decimals = 0) %>%
  fmt_number(R2:MKI, decimal = 3) %>%
  tab_style(style = cell_text(weight = "bold"), cells_title()) %>%
  tab_style(style = cell_text(weight = "bold"), cells_column_labels()) %>%
  extract_body() %>%
  # Replacing with non-line-break space characters for better formatting
  mutate(across(starts_with("Wall Time"), ~ gsub(" ", "&#160;", .x))) %>%
  rename(
    `Wall&#160;Time (Full&#160;Run)` = `Wall Time (Full Run)`,
    `Peak&#160;Device Utilization` = `Approx. Peak Device Utilization`
  ) %>%
  knitr::kable(format = "markdown", align = "llllrrrrllllll")
```

1. Categoricals with over 50 values are hashed, otherwise one-hot encoded.
2. Categoricals with over 50 values are hashed, otherwise natively handled.

## Hardware

These tests were run on two different machines: an on-prem modeling server used by the CCAO and a test server provided by NVIDIA via the [LaunchPad](https://www.nvidia.com/en-us/launchpad/) program. The machines have the following specifications:

|              | CCAO                                     | NVIDIA                                 |
|--------------|------------------------------------------|----------------------------------------|
| **CPU**      | Xeon Silver 4208 CPU @ 2.10GHz, 16 cores | Xeon Gold 6354 CPU @ 3.00GHz, 72 cores |
| **Memory**   | 128GiB                                   | 512GiB                                 |
| **GPU**      | -                                        | NVIDIA A40, 48GB                       |
| **OS**       | Ubuntu 22.04 LTS                         | Ubuntu 22.04 LTS                       |
| **Compiler** | gcc (11.4.0) -O3 -march=native           | gcc (11.4.0) -O3 -march=native         |

### Tasks

The tasks performed for this benchmark (outlined in the table above) are as follows:

- **Full Run** - The model is trained on the training + test set, to be used for prediction on unseen data.
- **Prediction** - The trained model is used to predict on the assessment data.
- **SHAP** - The trained model is used to predict SHAP values for the first 50K rows of assessment data.
- For performance metrics, the model is trained on a training set, then predicts on a holdout test set. Performance is calculated using the test set predictions.

### Inputs

The benchmark uses the following inputs:

- Input data from the 2023 CCAO residential valuation model:
  - [`input/training_data.parquet`](https://ccao-data-public-us-east-1.s3.amazonaws.com/models/inputs/res/2023/training_data.parquet) - 424,950 rows
  - [`input/assessment_data.parquet`](https://ccao-data-public-us-east-1.s3.amazonaws.com/models/inputs/res/2023/assessment_data.parquet) - 1,099,226 rows
- (Hyper)parameters used for this benchmark can be found in [`params.yaml`](./params.yaml)
